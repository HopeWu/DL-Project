{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVm9IYYlhpvN"
      },
      "source": [
        "# Plan\n",
        "Five models. Each one is hypertuned with respect to learning rate, unit number, optimizer, batch size, epoch, data normalization, dropout?, dropout rate, activation choice, \n",
        "\n",
        "The four models are \n",
        "- 1 mlp model\n",
        "- 1 vgg16 model\n",
        "- 1 yamnet\n",
        "- 1 LSTM\n",
        "- a hybrid of yamnet and LSTM\n",
        "\n",
        "The feature used\n",
        "- MFCCs for mlp\n",
        "- Mel Spectrogram for vgg16\n",
        "- raw audio waves for sound models\n",
        "\n",
        "Tuned hyper parameters\n",
        "- learning rate\n",
        "- unit number\n",
        "- structure, e.g. whether to contain one more layer, whether to contain dropout, whether to do data normalization\n",
        "- dropout rate\n",
        "- activation choice\n",
        "- batch size\n",
        "- epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdxGIkk5uSNy",
        "outputId": "63df2ca3-a053-47c6-fcb5-2af953934656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/176.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner -q\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras_tuner\n",
        "from tensorflow.keras import layers\n",
        "import librosa\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten, Conv2D,MaxPooling2D,LSTM\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from datetime import datetime \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# for manipulate the mel spectrographs\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZBt4Fu8v8UH"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lxMhKTSTi0n"
      },
      "source": [
        "## Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WSqqzodnQbF-"
      },
      "outputs": [],
      "source": [
        "# the root of the data\n",
        "dataRoot = \"drive/MyDrive/DeepLearningProject/datasets/Data/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgBvZmErm1B2"
      },
      "source": [
        "# LSTM with MFCCs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PichRE4tQYbC"
      },
      "source": [
        "### Load the audio wave files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ig9H21RmqQdT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "be4859c2-e02d-43bb-e062-599b787cccf5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'blues'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "'''\n",
        "@fileName - file name of a music\n",
        "return - the label\n",
        "e.g. label = extract_label(\"blues0000.png\")\n",
        "'''\n",
        "def extract_audio_label(fileName):\n",
        "  import re\n",
        "\n",
        "  match = re.search(r'([a-zA-Z ]+).(\\d+)', fileName)\n",
        "\n",
        "  if match:\n",
        "      # text = match.group(1).strip()\n",
        "      text = match.group(1)\n",
        "  else:\n",
        "    raise ValueError(\"Failed to extracte labels from Music file name, \"+fileName)\n",
        "\n",
        "  return text\n",
        "extract_audio_label(\"blues0000.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NLzlZGLSSxoc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea00ed2e-03c6-41a0-dc7b-cc47504f24f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-5f1e593bd6d8>:27: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  data,sample_rate=librosa.load(musicPath, sr=16000)\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error with  jazz.00054.wav   \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-5f1e593bd6d8>:36: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  waves = np.array(waves)\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Load audio wave files\n",
        "'''\n",
        "\n",
        "# Define the root directory\n",
        "root_dir = os.path.join(dataRoot, \"genres_original\")\n",
        "\n",
        "# Load the images and labels\n",
        "waves = []\n",
        "labels = []\n",
        "\n",
        "# Iterate through all directories under the root directory\n",
        "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
        "    # dirpath is the path of the current directory\n",
        "    # dirnames is a list of subdirectories in the current directory\n",
        "    # filenames is a list of files in the current directory\n",
        "    \n",
        "    # Do something with the directory path, such as print it\n",
        "    \n",
        "    # print(dirnames)\n",
        "    \n",
        "    for fname in filenames:\n",
        "      # deal with the music\n",
        "      musicPath = os.path.join(dirpath,fname)\n",
        "      # when have an exception, do not use this sample\n",
        "      try:\n",
        "        data,sample_rate=librosa.load(musicPath, sr=16000)\n",
        "        waves.append(data)\n",
        "        # get its label\n",
        "        labels.append(extract_audio_label(fname))\n",
        "      except Exception as e:\n",
        "        print(\"Error with \",fname, \" \",e)\n",
        "    \n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "waves = np.array(waves)\n",
        "labels = np.array(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADb8uz4422zx"
      },
      "source": [
        "## Make a 10 times larger dataset by extracting 10 3-second sub waves from the original 30-second wave"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Z9_xlqXA22z6"
      },
      "outputs": [],
      "source": [
        "def Split(audio, sr=16000):\n",
        "  # Get number of samples for 2 seconds; replace 2 by any number\n",
        "  buffer = 3 * sr\n",
        "\n",
        "  samples_total = len(audio)\n",
        "  samples_wrote = 0\n",
        "\n",
        "  splits = []\n",
        "  while samples_wrote < samples_total:\n",
        "\n",
        "      #check if the buffer is not exceeding total samples \n",
        "      if buffer > (samples_total - samples_wrote):\n",
        "          buffer = samples_total - samples_wrote\n",
        "\n",
        "      block = audio[samples_wrote : (samples_wrote + buffer)]\n",
        "      samples_wrote += buffer\n",
        "      splits.append(block)\n",
        "  return splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Y8IGPeE722z_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94430e59-dea8-4c55-b428-2dd8c4c346be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-d6965ef10353>:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  waves_3sec = np.array(waves_3sec)\n"
          ]
        }
      ],
      "source": [
        "waves_3sec = []\n",
        "labels_3sec = []\n",
        "for wave, label in zip(waves, labels):\n",
        "  splits = []\n",
        "  splits = Split(wave)\n",
        "  for split in splits:\n",
        "    waves_3sec.append(split)\n",
        "    labels_3sec.append(label)\n",
        "\n",
        "waves_3sec = np.array(waves_3sec)\n",
        "labels_3sec = np.array(labels_3sec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YM1B8uqyLJFs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e7e1547-b0f0-4616-9157-4a2403f1a721"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10979,)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "labels_3sec.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xa7LIGw1LU7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88a47856-1bca-41f1-b4c4-44adeed94810"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10979,)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "waves_3sec.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Q3ywZIUqLX1J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e2317ff-463b-480c-e306-dcc91d4a292b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48000,)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "waves_3sec[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4fWfs5PLq7t"
      },
      "source": [
        "### get rid of those of different shapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "scgY03A7Lxtr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2549b58-3ef7-4873-acf1-451aebc95855"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "998\n"
          ]
        }
      ],
      "source": [
        "# first count how many of them have different shapes\n",
        "count = 0\n",
        "for wave in waves_3sec:\n",
        "  if wave.shape[0] != 48000:\n",
        "    count+=1\n",
        "print(count)\n",
        "# only 1/10 of them are of other shapes, we can safely remove them without worrying about the balance of dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the distribution of the corrupted data\n",
        "distribution_corrupted = {}\n",
        "for i in range(waves_3sec.shape[0]):\n",
        "  if waves_3sec[i].shape[0] != 48000:\n",
        "    if labels_3sec[i] in distribution_corrupted:\n",
        "      distribution_corrupted[labels_3sec[i]] += 1\n",
        "    else:\n",
        "      distribution_corrupted[labels_3sec[i]] = 1\n",
        "print(distribution_corrupted)\n",
        "# they are equally distributed thus safe to delete"
      ],
      "metadata": {
        "id": "Ue8QfN502YaO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59efad31-76dd-45a1-d7c7-3949ca120c69"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'blues': 100, 'reggae': 100, 'classical': 100, 'hiphop': 100, 'jazz': 99, 'rock': 99, 'pop': 100, 'disco': 100, 'country': 100, 'metal': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_3nubCcM0zY"
      },
      "outputs": [],
      "source": [
        "waves_3sec_clear = []\n",
        "labels_3sec_clear = []\n",
        "\n",
        "for wave,label in zip(waves_3sec, labels_3sec):\n",
        "  if wave.shape[0] == 48000:\n",
        "    waves_3sec_clear.append(wave)\n",
        "    labels_3sec_clear.append(label)\n",
        "    \n",
        "waves_3sec_clear = np.array(waves_3sec_clear)\n",
        "labels_3sec_clear = np.array(labels_3sec_clear)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HMETHIqNW1i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e5dc85c-59a3-4331-c696-987c2132284d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9981, 48000)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "waves_3sec_clear.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGKDveegNiYT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "213b5a4a-b58e-49a0-961d-fd6eeb9102bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9981,)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "labels_3sec_clear.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZgZnLyPCAqQ"
      },
      "outputs": [],
      "source": [
        "waves_raw = waves_3sec_clear\n",
        "labels_raw = labels_3sec_clear"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "waves_raw.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TH5LAq04ycS",
        "outputId": "6a0d5bad-2447-424b-807e-a85cda5cf32a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9981, 48000)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEkTCTFIBBLB"
      },
      "source": [
        "### One note, when taking the a portion to do the hypertuning, shuffle the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get MFCCs features"
      ],
      "metadata": {
        "id": "hNbtb2SH4fBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "\n",
        "mfcc_features = []\n",
        "\n",
        "for wave in waves_raw:\n",
        "  # Extract MFCCs\n",
        "  mfccs = librosa.feature.mfcc(y=wave, sr=16000, n_mfcc=13)\n",
        "  mfcc_features.append(mfccs.T)"
      ],
      "metadata": {
        "id": "rLWSTEf14ke-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mfcc_features = np.array(mfcc_features)"
      ],
      "metadata": {
        "id": "BUA2K_vj58fO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mfcc_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43e8tLCJ9I9J",
        "outputId": "80b364d1-bd1e-45dd-bfe2-3c4c250c3d89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9981, 94, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mfcc_features[0][0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9o01kgK9kLKm",
        "outputId": "8fb20ef1-8738-4a9c-b81a-2ba4329a6829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-64.33838"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HK7CjzzSoMJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "672a9b17-4d0d-4f73-c30a-5763a92d029d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9981, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# encode the labels for large dataset\n",
        "labelDf_large = pd.DataFrame({\"label\":labels_3sec_clear})\n",
        "labelDf_large['label'].value_counts()\n",
        "label_dict_large = {}\n",
        "code = 0\n",
        "for _label in labelDf_large['label'].value_counts().index:\n",
        "  label_dict_large[_label] = code\n",
        "  code += 1\n",
        "\n",
        "labels_large_encoded = []\n",
        "labels_large = labelDf_large.values\n",
        "for _l in labels_large:\n",
        "  labels_large_encoded.append(label_dict_large[_l[0]])\n",
        "labels_large_encoded = np.array(labels_large_encoded)\n",
        "\n",
        "labels_large_encoded_ct = to_categorical(labels_large_encoded)\n",
        "labels_large_encoded_ct.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6P4716kWJTMm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "059fc9b6-a79a-4e22-b479-b354de637eee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 6\n",
            "units_1 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
            "units_2 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 32, 'sampling': 'linear'}\n",
            "dropout_2 (Boolean)\n",
            "{'default': False, 'conditions': []}\n",
            "units_3 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
            "dropout_rate2 (Float)\n",
            "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.26, 'step': 0.05, 'sampling': 'linear'}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001], 'ordered': True}\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "class LSTMHyperModel(keras_tuner.HyperModel):\n",
        "    def build(self, hp):\n",
        "        model = keras.Sequential()\n",
        "        # activatoin = hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
        "        activatoin = \"tanh\"\n",
        "\n",
        "        model.add(LSTM(\n",
        "              units = hp.Int(\"units_1\", 32, 512, step = 32),\n",
        "              activation = activatoin,\n",
        "              input_shape=(mfcc_features.shape[1], mfcc_features.shape[2]), \n",
        "              return_sequences=True)\n",
        "        )\n",
        "\n",
        "        model.add(LSTM(\n",
        "              units = hp.Int(\"units_2\", 32, 256, step = 32),\n",
        "              activation = activatoin,\n",
        "              return_sequences=True)\n",
        "        )\n",
        "        \n",
        "        if hp.Boolean(\"dropout_2\"):\n",
        "            model.add(Dropout(0.25))\n",
        "\n",
        "        model.add(LSTM(\n",
        "              units = hp.Int(\"units_3\", 16, 128, step = 32),\n",
        "              activation = activatoin)\n",
        "        )\n",
        "\n",
        "        model.add(Dropout(hp.Float(\"dropout_rate2\", 0.1, 0.26, step = 0.05)))\n",
        "\n",
        "        model.add(Dense(10, activation = \"softmax\"))  \n",
        "\n",
        "        # Define the optimizer learning rate as a hyperparameter.\n",
        "        learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3])\n",
        "\n",
        "        # Compile the model.\n",
        "        model.compile(\n",
        "            loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer = Adam(learning_rate=learning_rate),\n",
        "        )\n",
        "\n",
        "        return model\n",
        "\n",
        "    def fit(self, hp, model, X, y, **kwargs):\n",
        "\n",
        "        return model.fit(\n",
        "            X,\n",
        "            y,\n",
        "            validation_split=0.2,\n",
        "            batch_size = hp.Int(\"batch_size\", 4, 64,step = 8),\n",
        "            **kwargs,\n",
        "        )   \n",
        "        \n",
        "tuner_lstm = keras_tuner.RandomSearch(\n",
        "    LSTMHyperModel(),\n",
        "    objective=\"val_accuracy\",\n",
        "    overwrite=True,\n",
        "    executions_per_trial=2,\n",
        "    max_trials=10,\n",
        "    directory=\"lstm_tuner\",\n",
        "    project_name='lstm'\n",
        ")\n",
        "\n",
        "print(tuner_lstm.search_space_summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vV6Um93ERErV"
      },
      "outputs": [],
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(mfcc_features,labels_large_encoded_ct,test_size=0.2,random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mfcc_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1Hvt80_PCR1",
        "outputId": "2bb8529f-d4a2-4618-9c51-b3c9c080401c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9981, 94, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # a quick test\n",
        "# hp = keras_tuner.HyperParameters()\n",
        "# hypermodel = LSTMHyperModel()\n",
        "# model = hypermodel.build(hp)\n",
        "# hypermodel.fit(hp, model, X_train, y_train, epochs = 5)"
      ],
      "metadata": {
        "id": "2MZ75ok__eMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUc830dZKi4D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ad1ef51-82d9-40f7-df3c-26af031efc93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 00m 42s]\n",
            "val_accuracy: 0.4038822799921036\n",
            "\n",
            "Best val_accuracy So Far: 0.5961177051067352\n",
            "Total elapsed time: 00h 15m 22s\n"
          ]
        }
      ],
      "source": [
        "# early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "# uncomment this\n",
        "# tuner_lstm.search(X_train, y_train,callbacks = [keras.callbacks.TensorBoard(\"lstm_tuner\")], epochs = 5)\n",
        "# uncomment this\n",
        "tuner_lstm.search(X_train, y_train, epochs = 5, callbacks = [keras.callbacks.TensorBoard(\"lstm_tuner\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syaHDFxJJTMp"
      },
      "outputs": [],
      "source": [
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir mlp_tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0X6guM-5JTMq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f94a47e-ced9-445f-f7e5-2a9054d21888"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "533/533 [==============================] - 13s 15ms/step - loss: 1.7174 - accuracy: 0.3845 - val_loss: 1.4891 - val_accuracy: 0.4646\n",
            "Epoch 2/50\n",
            "533/533 [==============================] - 7s 13ms/step - loss: 1.4801 - accuracy: 0.4719 - val_loss: 1.4078 - val_accuracy: 0.5059\n",
            "Epoch 3/50\n",
            "533/533 [==============================] - 7s 13ms/step - loss: 1.3717 - accuracy: 0.5225 - val_loss: 1.4050 - val_accuracy: 0.4953\n",
            "Epoch 4/50\n",
            "533/533 [==============================] - 7s 13ms/step - loss: 1.2779 - accuracy: 0.5585 - val_loss: 1.3059 - val_accuracy: 0.5385\n",
            "Epoch 5/50\n",
            "533/533 [==============================] - 7s 13ms/step - loss: 1.1600 - accuracy: 0.6078 - val_loss: 1.1925 - val_accuracy: 0.5886\n",
            "Epoch 6/50\n",
            "533/533 [==============================] - 7s 13ms/step - loss: 1.0475 - accuracy: 0.6490 - val_loss: 1.1483 - val_accuracy: 0.6174\n",
            "Epoch 7/50\n",
            "533/533 [==============================] - 7s 13ms/step - loss: 0.9814 - accuracy: 0.6731 - val_loss: 1.0511 - val_accuracy: 0.6556\n",
            "Epoch 8/50\n",
            "533/533 [==============================] - 7s 13ms/step - loss: 0.8958 - accuracy: 0.7021 - val_loss: 1.1072 - val_accuracy: 0.6318\n",
            "Epoch 9/50\n",
            "533/533 [==============================] - 7s 13ms/step - loss: 0.8158 - accuracy: 0.7285 - val_loss: 0.9948 - val_accuracy: 0.6662\n",
            "Epoch 10/50\n",
            "533/533 [==============================] - 7s 13ms/step - loss: 0.7518 - accuracy: 0.7558 - val_loss: 0.9139 - val_accuracy: 0.7063\n",
            "Epoch 11/50\n",
            "533/533 [==============================] - 7s 13ms/step - loss: 0.6597 - accuracy: 0.7853 - val_loss: 0.9727 - val_accuracy: 0.6944\n",
            "Epoch 12/50\n",
            "533/533 [==============================] - 7s 13ms/step - loss: 0.6153 - accuracy: 0.8040 - val_loss: 0.8952 - val_accuracy: 0.7195\n",
            "Epoch 13/50\n",
            "533/533 [==============================] - 7s 13ms/step - loss: 0.5518 - accuracy: 0.8229 - val_loss: 0.8266 - val_accuracy: 0.7495\n",
            "Epoch 14/50\n",
            "533/533 [==============================] - 7s 13ms/step - loss: 0.4980 - accuracy: 0.8477 - val_loss: 0.8459 - val_accuracy: 0.7451\n",
            "Epoch 15/50\n",
            "533/533 [==============================] - 7s 13ms/step - loss: 0.4583 - accuracy: 0.8519 - val_loss: 0.8218 - val_accuracy: 0.7464\n",
            "Epoch 16/50\n",
            "533/533 [==============================] - 7s 13ms/step - loss: 0.4252 - accuracy: 0.8657 - val_loss: 0.7878 - val_accuracy: 0.7589\n",
            "Epoch 17/50\n",
            "533/533 [==============================] - 7s 13ms/step - loss: 0.3887 - accuracy: 0.8773 - val_loss: 0.8909 - val_accuracy: 0.7439\n",
            "Epoch 18/50\n",
            "533/533 [==============================] - 7s 13ms/step - loss: 0.3912 - accuracy: 0.8766 - val_loss: 0.8812 - val_accuracy: 0.7495\n",
            "Epoch 19/50\n",
            "533/533 [==============================] - 7s 13ms/step - loss: 0.3483 - accuracy: 0.8866 - val_loss: 0.8188 - val_accuracy: 0.7664\n",
            "Epoch 20/50\n",
            "533/533 [==============================] - 7s 14ms/step - loss: 0.3195 - accuracy: 0.9026 - val_loss: 0.8923 - val_accuracy: 0.7426\n",
            "Epoch 21/50\n",
            "533/533 [==============================] - 7s 13ms/step - loss: 0.2820 - accuracy: 0.9100 - val_loss: 0.8338 - val_accuracy: 0.7677\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4ec1832fe0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "lstm_hp_model = LSTMHyperModel()\n",
        "best_lstm_hp = tuner_lstm.get_best_hyperparameters()[0]\n",
        "best_lstm_model = lstm_hp_model.build(best_lstm_hp)\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
        "lstm_hp_model.fit(best_lstm_hp, best_lstm_model, X_train, y_train, verbose=1, epochs = 50, callbacks = [early_stop])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_lstm_model.save_weights(\"best_lstm_model.h5\")"
      ],
      "metadata": {
        "id": "D6Oy_tgod2-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy on the test set\n",
        "test_accuracy_lstm = best_lstm_model.evaluate(X_test,y_test,verbose=1)\n",
        "print(test_accuracy_lstm[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fip9b1eid5rV",
        "outputId": "20d2f5fc-9943-4fe2-f22e-082233b2542f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 6ms/step - loss: 0.7580 - accuracy: 0.7732\n",
            "0.7731597423553467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_lstm_hp.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "by9TaRbTTzSE",
        "outputId": "38cfc20e-712d-4e44-f12f-6e6707003abe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'units_1': 416,\n",
              " 'units_2': 32,\n",
              " 'dropout_2': True,\n",
              " 'units_3': 48,\n",
              " 'dropout_rate2': 0.2,\n",
              " 'learning_rate': 0.001,\n",
              " 'batch_size': 12}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr0-0TpTyH0t"
      },
      "source": [
        "# LSTM Summary\n",
        "Best accuracy, *77.3%*, at epochs of 10 on,\n",
        "```python\n",
        "{\n",
        " 'units_1': 416, 'units_2': 32, 'dropout_2': True,\n",
        " 'units_3': 48, 'dropout_rate2': 0.2, 'learning_rate': 0.001,\n",
        " 'batch_size': 12, 'epochs': 16\n",
        " }\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}