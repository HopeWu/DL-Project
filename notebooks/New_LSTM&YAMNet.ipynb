{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVm9IYYlhpvN"
      },
      "source": [
        "# Plan\n",
        "Five models. Each one is hypertuned with respect to learning rate, unit number, optimizer, batch size, epoch, data normalization, dropout?, dropout rate, activation choice, \n",
        "\n",
        "The four models are \n",
        "- 1 mlp model\n",
        "- 1 vgg16 model\n",
        "- 1 yamnet\n",
        "- 1 LSTM\n",
        "- a hybrid of yamnet and LSTM\n",
        "\n",
        "The feature used\n",
        "- MFCCs for mlp\n",
        "- Mel Spectrogram for vgg16\n",
        "- raw audio waves for sound models\n",
        "\n",
        "Tuned hyper parameters\n",
        "- learning rate\n",
        "- unit number\n",
        "- structure, e.g. whether to contain one more layer, whether to contain dropout, whether to do data normalization\n",
        "- dropout rate\n",
        "- activation choice\n",
        "- batch size\n",
        "- epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdxGIkk5uSNy",
        "outputId": "6a820368-3fcd-449e-aa55-661ac3e876ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/176.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m174.1/176.1 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner -q\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras_tuner\n",
        "from tensorflow.keras import layers\n",
        "import librosa\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten, Conv2D,MaxPooling2D,LSTM\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from datetime import datetime \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# for manipulate the mel spectrographs\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZBt4Fu8v8UH"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lxMhKTSTi0n"
      },
      "source": [
        "## Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WSqqzodnQbF-"
      },
      "outputs": [],
      "source": [
        "# the root of the data\n",
        "dataRoot = \"drive/MyDrive/DeepLearningProject/datasets/Data/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgBvZmErm1B2"
      },
      "source": [
        "# LSTM with MFCCs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PichRE4tQYbC"
      },
      "source": [
        "### Load the audio wave files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ig9H21RmqQdT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7def87d9-22fe-403f-82dc-3bd4e8aa1a66"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'blues'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "'''\n",
        "@fileName - file name of a music\n",
        "return - the label\n",
        "e.g. label = extract_label(\"blues0000.png\")\n",
        "'''\n",
        "def extract_audio_label(fileName):\n",
        "  import re\n",
        "\n",
        "  match = re.search(r'([a-zA-Z ]+).(\\d+)', fileName)\n",
        "\n",
        "  if match:\n",
        "      # text = match.group(1).strip()\n",
        "      text = match.group(1)\n",
        "  else:\n",
        "    raise ValueError(\"Failed to extracte labels from Music file name, \"+fileName)\n",
        "\n",
        "  return text\n",
        "extract_audio_label(\"blues0000.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NLzlZGLSSxoc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59a4f877-f3ff-48ca-86cd-81b77f88e101"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-5f1e593bd6d8>:27: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  data,sample_rate=librosa.load(musicPath, sr=16000)\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error with  jazz.00054.wav   \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-5f1e593bd6d8>:36: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  waves = np.array(waves)\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Load audio wave files\n",
        "'''\n",
        "\n",
        "# Define the root directory\n",
        "root_dir = os.path.join(dataRoot, \"genres_original\")\n",
        "\n",
        "# Load the images and labels\n",
        "waves = []\n",
        "labels = []\n",
        "\n",
        "# Iterate through all directories under the root directory\n",
        "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
        "    # dirpath is the path of the current directory\n",
        "    # dirnames is a list of subdirectories in the current directory\n",
        "    # filenames is a list of files in the current directory\n",
        "    \n",
        "    # Do something with the directory path, such as print it\n",
        "    \n",
        "    # print(dirnames)\n",
        "    \n",
        "    for fname in filenames:\n",
        "      # deal with the music\n",
        "      musicPath = os.path.join(dirpath,fname)\n",
        "      # when have an exception, do not use this sample\n",
        "      try:\n",
        "        data,sample_rate=librosa.load(musicPath, sr=16000)\n",
        "        waves.append(data)\n",
        "        # get its label\n",
        "        labels.append(extract_audio_label(fname))\n",
        "      except Exception as e:\n",
        "        print(\"Error with \",fname, \" \",e)\n",
        "    \n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "waves = np.array(waves)\n",
        "labels = np.array(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADb8uz4422zx"
      },
      "source": [
        "## Make a 10 times larger dataset by extracting 10 3-second sub waves from the original 30-second wave"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Z9_xlqXA22z6"
      },
      "outputs": [],
      "source": [
        "def Split(audio, sr=16000):\n",
        "  # Get number of samples for 2 seconds; replace 2 by any number\n",
        "  buffer = 3 * sr\n",
        "\n",
        "  samples_total = len(audio)\n",
        "  samples_wrote = 0\n",
        "\n",
        "  splits = []\n",
        "  while samples_wrote < samples_total:\n",
        "\n",
        "      #check if the buffer is not exceeding total samples \n",
        "      if buffer > (samples_total - samples_wrote):\n",
        "          buffer = samples_total - samples_wrote\n",
        "\n",
        "      block = audio[samples_wrote : (samples_wrote + buffer)]\n",
        "      samples_wrote += buffer\n",
        "      splits.append(block)\n",
        "  return splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Y8IGPeE722z_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61023686-3972-4028-e430-3c444b2caa62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-d6965ef10353>:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  waves_3sec = np.array(waves_3sec)\n"
          ]
        }
      ],
      "source": [
        "waves_3sec = []\n",
        "labels_3sec = []\n",
        "for wave, label in zip(waves, labels):\n",
        "  splits = []\n",
        "  splits = Split(wave)\n",
        "  for split in splits:\n",
        "    waves_3sec.append(split)\n",
        "    labels_3sec.append(label)\n",
        "\n",
        "waves_3sec = np.array(waves_3sec)\n",
        "labels_3sec = np.array(labels_3sec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YM1B8uqyLJFs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96ecef6a-7e09-46a1-bc28-ff60981f77bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10979,)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "labels_3sec.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xa7LIGw1LU7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da44da0a-299f-4f3f-d0a1-8f218163c19b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10979,)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "waves_3sec.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Q3ywZIUqLX1J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "757bf733-e482-4ac6-c83b-c5c4a5bfe78b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48000,)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "waves_3sec[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4fWfs5PLq7t"
      },
      "source": [
        "### get rid of those of different shapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "scgY03A7Lxtr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "499f2e66-c883-4a1a-9f30-d9ce39cac6d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "998\n"
          ]
        }
      ],
      "source": [
        "# first count how many of them have different shapes\n",
        "count = 0\n",
        "for wave in waves_3sec:\n",
        "  if wave.shape[0] != 48000:\n",
        "    count+=1\n",
        "print(count)\n",
        "# only 1/10 of them are of other shapes, we can safely remove them without worrying about the balance of dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "f_3nubCcM0zY"
      },
      "outputs": [],
      "source": [
        "waves_3sec_clear = []\n",
        "labels_3sec_clear = []\n",
        "\n",
        "for wave,label in zip(waves_3sec, labels_3sec):\n",
        "  if wave.shape[0] == 48000:\n",
        "    waves_3sec_clear.append(wave)\n",
        "    labels_3sec_clear.append(label)\n",
        "    \n",
        "waves_3sec_clear = np.array(waves_3sec_clear)\n",
        "labels_3sec_clear = np.array(labels_3sec_clear)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-HMETHIqNW1i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8efe1b6-86bc-4095-e296-cebcc3ebc983"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9981, 48000)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "waves_3sec_clear.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MGKDveegNiYT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e53546d-c4ab-4036-94c4-e1060d3fe7d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9981,)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "labels_3sec_clear.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encode the labels for large dataset\n",
        "labelDf_large = pd.DataFrame({\"label\":labels_3sec_clear})\n",
        "labelDf_large['label'].value_counts()\n",
        "label_dict_large = {}\n",
        "code = 0\n",
        "for _label in labelDf_large['label'].value_counts().index:\n",
        "  label_dict_large[_label] = code\n",
        "  code += 1\n",
        "\n",
        "labels_large_encoded = []\n",
        "labels_large = labelDf_large.values\n",
        "for _l in labels_large:\n",
        "  labels_large_encoded.append(label_dict_large[_l[0]])\n",
        "labels_large_encoded = np.array(labels_large_encoded)\n",
        "\n",
        "labels_large_encoded_ct = to_categorical(labels_large_encoded)\n",
        "labels_large_encoded_ct.shape"
      ],
      "metadata": {
        "id": "aF24_lzaehBT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b456ad24-eeee-4ed8-a160-b0b47a0a6500"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9981, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "UZgZnLyPCAqQ"
      },
      "outputs": [],
      "source": [
        "waves_raw = waves_3sec_clear\n",
        "labels_raw = labels_3sec_clear"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEkTCTFIBBLB"
      },
      "source": [
        "### One note, when taking the a portion to do the hypertuning, shuffle the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vkNL_37BxmO"
      },
      "source": [
        "# Get YAMNet features"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "I_U4-l3V39CD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OD_9AXvemYLK"
      },
      "outputs": [],
      "source": [
        "# load the pretrained model\n",
        "yamnet_model = hub.load('https://tfhub.dev/google/yamnet/1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "EVhkQ9XGmBOY"
      },
      "outputs": [],
      "source": [
        "# make inference to extract yamnet features\n",
        "yamnet_features = []\n",
        "for wave in waves_raw:\n",
        "  _,embeddings,_ = yamnet_model(wave)\n",
        "  yamnet_features.append(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "KEPp3m9FmnYo"
      },
      "outputs": [],
      "source": [
        "yamnet_features = np.array(yamnet_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "IFzbq2uumfUq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6010e8f-f728-4176-e0ec-fba8a8a7bce8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9981, 6, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "yamnet_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6P4716kWJTMm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3f2dbb5-518a-4383-ccd0-6e3360101820"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 8\n",
            "units_1 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
            "dropout_rate1 (Float)\n",
            "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.26, 'step': 0.05, 'sampling': 'linear'}\n",
            "units_2 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 32, 'sampling': 'linear'}\n",
            "has_additional_layer (Boolean)\n",
            "{'default': False, 'conditions': []}\n",
            "dropout_2 (Boolean)\n",
            "{'default': False, 'conditions': []}\n",
            "units_3 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
            "dropout_rate2 (Float)\n",
            "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.26, 'step': 0.05, 'sampling': 'linear'}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001], 'ordered': True}\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "class LSTMYAMHyperModel(keras_tuner.HyperModel):\n",
        "    def build(self, hp):\n",
        "        model = keras.Sequential()\n",
        "        # activatoin = hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
        "        activatoin = \"tanh\"\n",
        "\n",
        "        model.add(LSTM(\n",
        "              units = hp.Int(\"units_1\", 32, 512, step = 32),\n",
        "              activation = activatoin,\n",
        "              input_shape=(yamnet_features.shape[1], yamnet_features.shape[2]), \n",
        "              return_sequences=True)\n",
        "        )\n",
        "        model.add(Dropout(hp.Float(\"dropout_rate1\", 0.1, 0.26, step = 0.05)))\n",
        "\n",
        "        model.add(LSTM(\n",
        "              units = hp.Int(\"units_2\", 32, 256, step = 32),\n",
        "              activation = activatoin,\n",
        "              return_sequences=True)\n",
        "        )\n",
        "\n",
        "        if hp.Boolean(\"has_additional_layer\"):\n",
        "          model.add(LSTM(\n",
        "              units = hp.Int(\"units_additional\", 32, 256, step = 32),\n",
        "              activation = activatoin,\n",
        "              return_sequences=True)\n",
        "          )\n",
        "        \n",
        "        if hp.Boolean(\"dropout_2\"):\n",
        "            model.add(Dropout(0.25))\n",
        "\n",
        "        model.add(LSTM(\n",
        "              units = hp.Int(\"units_3\", 16, 128, step = 32),\n",
        "              activation = activatoin)\n",
        "        )\n",
        "\n",
        "        model.add(Dropout(hp.Float(\"dropout_rate2\", 0.1, 0.26, step = 0.05)))\n",
        "\n",
        "        model.add(Dense(10, activation = \"softmax\"))  \n",
        "\n",
        "        # Define the optimizer learning rate as a hyperparameter.\n",
        "        learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3])\n",
        "\n",
        "        # Compile the model.\n",
        "        model.compile(\n",
        "            loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer = Adam(learning_rate=learning_rate),\n",
        "        )\n",
        "\n",
        "        return model\n",
        "\n",
        "    def fit(self, hp, model, X, y, **kwargs):\n",
        "\n",
        "        return model.fit(\n",
        "            X,\n",
        "            y,\n",
        "            validation_split=0.2,\n",
        "            batch_size = hp.Int(\"batch_size\", 4, 64,step = 8),\n",
        "            **kwargs,\n",
        "        )   \n",
        "        \n",
        "tuner_lstmYam = keras_tuner.RandomSearch(\n",
        "    LSTMYAMHyperModel(),\n",
        "    objective=\"val_accuracy\",\n",
        "    overwrite=True,\n",
        "    executions_per_trial=2,\n",
        "    max_trials=20,\n",
        "    directory=\"lstmYam_tuner\",\n",
        "    project_name='lstmYam'\n",
        ")\n",
        "\n",
        "print(tuner_lstmYam.search_space_summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vV6Um93ERErV"
      },
      "outputs": [],
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(yamnet_features,labels_large_encoded_ct,test_size=0.2,random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "YUc830dZKi4D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24720cd3-07f9-4486-e7b8-3e12408f39ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 20 Complete [00h 00m 49s]\n",
            "val_accuracy: 0.7520350515842438\n",
            "\n",
            "Best val_accuracy So Far: 0.8284282982349396\n",
            "Total elapsed time: 00h 20m 27s\n"
          ]
        }
      ],
      "source": [
        "# early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "# uncomment this\n",
        "# tuner_lstmYam.search(X_train, y_train,callbacks = [keras.callbacks.TensorBoard(\"lstmYam_tuner\")], epochs = 5)\n",
        "tuner_lstmYam.search(X_train, y_train, epochs = 5, callbacks = [keras.callbacks.TensorBoard(\"lstmYam_tuner\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "syaHDFxJJTMp"
      },
      "outputs": [],
      "source": [
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir mlp_tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "0X6guM-5JTMq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9d8f84e-f4f1-43e4-83c8-3b1ded76df01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "146/146 [==============================] - 7s 15ms/step - loss: 0.8963 - accuracy: 0.7194 - val_loss: 0.7256 - val_accuracy: 0.7708\n",
            "Epoch 2/50\n",
            "146/146 [==============================] - 1s 8ms/step - loss: 0.6465 - accuracy: 0.7927 - val_loss: 0.6121 - val_accuracy: 0.7921\n",
            "Epoch 3/50\n",
            "146/146 [==============================] - 1s 8ms/step - loss: 0.5328 - accuracy: 0.8232 - val_loss: 0.6172 - val_accuracy: 0.7996\n",
            "Epoch 4/50\n",
            "146/146 [==============================] - 1s 8ms/step - loss: 0.4825 - accuracy: 0.8445 - val_loss: 0.6015 - val_accuracy: 0.8034\n",
            "Epoch 5/50\n",
            "146/146 [==============================] - 1s 8ms/step - loss: 0.4225 - accuracy: 0.8633 - val_loss: 0.5544 - val_accuracy: 0.8172\n",
            "Epoch 6/50\n",
            "146/146 [==============================] - 1s 8ms/step - loss: 0.3721 - accuracy: 0.8777 - val_loss: 0.5775 - val_accuracy: 0.8278\n",
            "Epoch 7/50\n",
            "146/146 [==============================] - 1s 8ms/step - loss: 0.3139 - accuracy: 0.8978 - val_loss: 0.5982 - val_accuracy: 0.8253\n",
            "Epoch 8/50\n",
            "146/146 [==============================] - 1s 8ms/step - loss: 0.2788 - accuracy: 0.9072 - val_loss: 0.5600 - val_accuracy: 0.8272\n",
            "Epoch 9/50\n",
            "146/146 [==============================] - 1s 8ms/step - loss: 0.2422 - accuracy: 0.9170 - val_loss: 0.6608 - val_accuracy: 0.8247\n",
            "Epoch 10/50\n",
            "146/146 [==============================] - 1s 8ms/step - loss: 0.2160 - accuracy: 0.9314 - val_loss: 0.5799 - val_accuracy: 0.8478\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faaa81de560>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "lstmYamnet_hp_model = LSTMYAMHyperModel()\n",
        "best_lstmYamnet_hp = tuner_lstmYam.get_best_hyperparameters()[0]\n",
        "best_lstmYamnet_model = lstmYamnet_hp_model.build(best_lstmYamnet_hp)\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
        "lstmYamnet_hp_model.fit(best_lstmYamnet_hp, best_lstmYamnet_model, X_train, y_train, verbose=1, epochs = 50, callbacks=[early_stop])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_lstmYamnet_model.save_weights('best_lstmYamnet_model.h5')"
      ],
      "metadata": {
        "id": "wlQCTqhydiAV"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy on the test set\n",
        "test_accuracy_lstmYamnet = best_lstmYamnet_model.evaluate(X_test,y_test,verbose=1)\n",
        "print(test_accuracy_lstmYamnet[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1acm38Odmvp",
        "outputId": "7e15a274-788a-4f1b-865d-6af4ab8329a9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 4ms/step - loss: 0.5655 - accuracy: 0.8423\n",
            "0.842263400554657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_lstmYamnet_hp.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYKZM3iDqGz2",
        "outputId": "562d6e22-b3b8-4b3e-eb02-c6685276c811"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'units_1': 480,\n",
              " 'dropout_rate1': 0.15000000000000002,\n",
              " 'units_2': 128,\n",
              " 'has_additional_layer': False,\n",
              " 'dropout_2': False,\n",
              " 'units_3': 80,\n",
              " 'dropout_rate2': 0.25,\n",
              " 'learning_rate': 0.001,\n",
              " 'units_additional': 64,\n",
              " 'batch_size': 44}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr0-0TpTyH0t"
      },
      "source": [
        "# LSTMYAMNet Summary\n",
        "Best accuracy, *84.2%*, at epochs of 10 on,\n",
        "```python\n",
        "{\n",
        " 'units_1': 480, 'dropout_rate1': 0.15, 'units_2': 128,\n",
        " 'has_additional_layer': False, 'dropout_2': False, \n",
        " 'units_3': 80, 'dropout_rate2': 0.25, 'learning_rate': 0.001,\n",
        " 'units_additional': 64, 'batch_size': 44\n",
        " }\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}