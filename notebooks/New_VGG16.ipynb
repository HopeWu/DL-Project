{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVm9IYYlhpvN"
      },
      "source": [
        "# Plan\n",
        "Five models. Each one is hypertuned with respect to learning rate, unit number, optimizer, batch size, epoch, data normalization, dropout?, dropout rate, activation choice, \n",
        "\n",
        "The four models are \n",
        "- 1 mlp model\n",
        "- 1 vgg16 model\n",
        "- 1 yamnet\n",
        "- 1 LSTM\n",
        "- a hybrid of yamnet and LSTM\n",
        "\n",
        "The feature used\n",
        "- MFCCs for mlp\n",
        "- Mel Spectrogram for vgg16\n",
        "- raw audio waves for sound models\n",
        "\n",
        "Tuned hyper parameters\n",
        "- learning rate\n",
        "- unit number\n",
        "- structure, e.g. whether to contain one more layer, whether to contain dropout, whether to do data normalization\n",
        "- dropout rate\n",
        "- activation choice\n",
        "- batch size\n",
        "- epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdxGIkk5uSNy",
        "outputId": "286bd6bc-0962-4b1f-e5a8-df0c2977271f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/176.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m174.1/176.1 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner -q\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras_tuner\n",
        "from tensorflow.keras import layers\n",
        "import librosa\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten, Conv2D,MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from datetime import datetime \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# for manipulate the mel spectrographs\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZBt4Fu8v8UH"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lxMhKTSTi0n"
      },
      "source": [
        "## Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WSqqzodnQbF-"
      },
      "outputs": [],
      "source": [
        "# the root of the data\n",
        "dataRoot = \"drive/MyDrive/DeepLearningProject/datasets/Data/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTXslufA8E3p"
      },
      "source": [
        "# VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zGDkpxSSLRPy"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4_uIKCaZFGbH",
        "outputId": "f2679563-5fc7-48b5-cb07-ef6bc4e5bb81"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'blues'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "'''\n",
        "A helper function to extract the labels from the file names\n",
        "@fileName - file name of a music\n",
        "return - the label\n",
        "e.g. label = extract_label(\"blues0000.png\")\n",
        "'''\n",
        "def extract_label(fileName):\n",
        "  import re\n",
        "\n",
        "  match = re.search(r'([a-zA-Z ]+)(\\d+)', fileName)\n",
        "\n",
        "  if match:\n",
        "      # text = match.group(1).strip()\n",
        "      text = match.group(1)\n",
        "  else:\n",
        "    raise ValueError(\"Failed to extracte labels from Music file name, \"+fileName)\n",
        "\n",
        "  return text\n",
        "extract_label(\"blues0000.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Ng5z6UEzGTk2"
      },
      "outputs": [],
      "source": [
        "# Define the root directory\n",
        "root_dir = os.path.join(dataRoot, \"images_original\")\n",
        "\n",
        "target_size = (224, 224)\n",
        "\n",
        "# save the images and labels\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Iterate through all directories under the root directory\n",
        "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
        "    # dirpath is the path of the current directory\n",
        "    # dirnames is a list of subdirectories in the current directory\n",
        "    # filenames is a list of files in the current directory\n",
        "    \n",
        "    # Do something with the directory path, such as print it\n",
        "    \n",
        "    # print(dirnames)\n",
        "    \n",
        "    for fname in filenames:\n",
        "      # deal with the music\n",
        "      musicPath = os.path.join(dirpath,fname)\n",
        "      music = Image.open(musicPath)\n",
        "\n",
        "      music = music.convert('RGB')\n",
        "      # music = music.resize((150,150))\n",
        "      music = np.array(music)\n",
        "      images.append(music)\n",
        "\n",
        "      # get its label\n",
        "      labels.append(extract_label(fname))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Py2tZewwEnbL"
      },
      "outputs": [],
      "source": [
        "# Convert the lists to NumPy arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkc4LKJNkvt4",
        "outputId": "80ea96f5-2883-4dc0-9415-28a121042381"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(288, 432, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "images[10].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-lMx11VBc23",
        "outputId": "8f811dfc-33a5-4620-ff92-4b5fa4e262d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "source": [
        "## Loading VGG16 model\n",
        "vgg16_base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=images[0].shape)\n",
        "\n",
        "## will not train base mode\n",
        "vgg16_base_model.trainable = False "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnDmo1VIOWcl",
        "outputId": "c70c1a0a-ff3f-4071-dada-f6f0918f734a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(288, 432, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "images[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpDlvf2U7JLz",
        "outputId": "0a8f7fab-c2ff-4304-b93f-4936b8c31395"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(999, 288, 432, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIM-P-p9Wvpj",
        "outputId": "a3ea4867-8e05-42a3-f7e7-e5c51d1f6096"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(999,)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXjME0z3b9mL",
        "outputId": "e9475aeb-cff2-4f4a-9dfc-9b16a0159cf8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "blues        100\n",
              "metal        100\n",
              "hiphop       100\n",
              "rock         100\n",
              "disco        100\n",
              "country      100\n",
              "pop          100\n",
              "reggae       100\n",
              "classical    100\n",
              "jazz          99\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# check whether we got every music by comparing the total numbers\n",
        "labelsDf = pd.DataFrame(columns=['label'])\n",
        "for dirpath, dirnames, filenames in os.walk(root_dir):    \n",
        "    for fname in filenames:\n",
        "      newRow = pd.DataFrame({'label': [extract_label(fname)]})\n",
        "      labelsDf = pd.concat([labelsDf, newRow])\n",
        "labelsDf['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTBLPdMInBpn",
        "outputId": "d0773bd3-2679-4951-f579-bdc86f7d075f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'blues': 0,\n",
              " 'metal': 1,\n",
              " 'hiphop': 2,\n",
              " 'rock': 3,\n",
              " 'disco': 4,\n",
              " 'country': 5,\n",
              " 'pop': 6,\n",
              " 'reggae': 7,\n",
              " 'classical': 8,\n",
              " 'jazz': 9}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# this dict is used to convert string labels to numerical labels\n",
        "labelsDf['label'].value_counts()\n",
        "label_dict = {}\n",
        "code = 0\n",
        "for _label in labelsDf['label'].value_counts().index:\n",
        "  label_dict[_label] = code\n",
        "  code += 1\n",
        "label_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fuXKMtuso_H_"
      },
      "outputs": [],
      "source": [
        "# encoding\n",
        "labels_encoded = []\n",
        "for _l in labels:\n",
        "  labels_encoded.append(label_dict[_l])\n",
        "labels_encoded = np.array(labels_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkixLRA2phWN",
        "outputId": "9d37254e-c904-4728-9930-e3a2a0dc2017"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(999,)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "labels_encoded.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ew5hMAH7rkXd",
        "outputId": "a084cfdb-8c9d-40fb-d6bf-e1d4df323150"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label_code\n",
              "0             100\n",
              "1             100\n",
              "2             100\n",
              "3             100\n",
              "4             100\n",
              "5             100\n",
              "6             100\n",
              "7             100\n",
              "8             100\n",
              "9              99\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# check the distribution of the data. One short but it's okay.\n",
        "dfLabel = pd.DataFrame({\"label_code\": labels_encoded})\n",
        "dfLabel[['label_code']].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvQ1kMZFpnLO",
        "outputId": "0e4cae39-c35b-4829-bb5b-7eb820b4cdb7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(999, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "labels_encoded_ct = to_categorical(labels_encoded)\n",
        "labels_encoded_ct.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "r1cHxr1G4T9p"
      },
      "outputs": [],
      "source": [
        "### Number of classes\n",
        "num_labels=labels_encoded_ct.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "FskSOY1lKW5V"
      },
      "outputs": [],
      "source": [
        "imgShape = np.array(images[0]).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ZYUUALPX8ahu"
      },
      "outputs": [],
      "source": [
        "images_cleaned = preprocess_input(images)\n",
        "images_cleaned.shape\n",
        "\n",
        "images_scaled = images/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNEBD1DNrBjy",
        "outputId": "44226548-4ec4-487a-fd78-bdb58e15d6bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 10s 56ms/step\n"
          ]
        }
      ],
      "source": [
        "# prepare the training and testing data\n",
        "\n",
        "method = 0;\n",
        "\n",
        "# extract features\n",
        "if method == 0:\n",
        "  vgg16features = vgg16_base_model.predict(images)\n",
        "if method == 1:\n",
        "  vgg16features = vgg16_base_model.predict(images_scaled)\n",
        "if method == 2:\n",
        "  vgg16features = vgg16_base_model.predict(images_cleaned)\n",
        "\n",
        "\n",
        "### Train Test Split\n",
        "X_cnn_train, X_cnn_test, y_cnn_train, y_cnn_test = train_test_split(vgg16features,labels_encoded_ct,test_size=0.2,random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "X0uo1CrFQvzK"
      },
      "outputs": [],
      "source": [
        "# do inference, i.e. get features from vgg16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "763dLuO8KbWc",
        "outputId": "df8aa243-0ca0-4289-b187-4487f7a705a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 10\n",
            "activation (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n",
            "units_1 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 1024, 'max_value': 3072, 'step': 512, 'sampling': 'linear'}\n",
            "dropout_1 (Boolean)\n",
            "{'default': False, 'conditions': []}\n",
            "units_2 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 512, 'max_value': 3072, 'step': 512, 'sampling': 'linear'}\n",
            "dropout_2 (Boolean)\n",
            "{'default': False, 'conditions': []}\n",
            "units_3 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 1024, 'step': 64, 'sampling': 'linear'}\n",
            "dropout_3 (Boolean)\n",
            "{'default': False, 'conditions': []}\n",
            "has_forth_layer (Boolean)\n",
            "{'default': False, 'conditions': []}\n",
            "dropout_4 (Boolean)\n",
            "{'default': False, 'conditions': []}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001], 'ordered': True}\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "class VGG16HyperModel(keras_tuner.HyperModel):\n",
        "    def build(self, hp):\n",
        "        model = keras.Sequential()\n",
        "\n",
        "        model.add(Flatten())\n",
        "        \n",
        "        activatoin = hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
        "\n",
        "        model.add(Dense(\n",
        "              units = hp.Int(\"units_1\", 1024, 3072, step = 512),\n",
        "              activation = activatoin)\n",
        "        )\n",
        "        if hp.Boolean(\"dropout_1\"):\n",
        "            model.add(Dropout(0.25))\n",
        "\n",
        "        model.add(Dense(\n",
        "              units = hp.Int(\"units_2\", 512, 3072, step = 512),\n",
        "              activation = activatoin)\n",
        "        )\n",
        "        if hp.Boolean(\"dropout_2\"):\n",
        "            model.add(Dropout(0.25))\n",
        "\n",
        "        model.add(Dense(\n",
        "              units = hp.Int(\"units_3\", 32, 1024, step = 64),\n",
        "              activation = activatoin)\n",
        "        )\n",
        "        if hp.Boolean(\"dropout_3\"):\n",
        "            model.add(Dropout(0.25))\n",
        "\n",
        "        if hp.Boolean(\"has_forth_layer\"):\n",
        "              model.add(Dense(\n",
        "                units = hp.Int(\"units_4\", 32, 1024, step = 64),\n",
        "                activation = activatoin)\n",
        "        )\n",
        "        if hp.Boolean(\"dropout_4\"):\n",
        "              model.add(Dropout(0.25))\n",
        "\n",
        "        model.add(Dense(num_labels, activation = \"softmax\"))  \n",
        "\n",
        "        # Define the optimizer learning rate as a hyperparameter.\n",
        "        learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3])\n",
        "\n",
        "        # Compile the model.\n",
        "        model.compile(\n",
        "            loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer = Adam(learning_rate=learning_rate),\n",
        "        )\n",
        "\n",
        "        return model\n",
        "\n",
        "    def fit(self, hp, model, X, y, **kwargs):\n",
        "\n",
        "        return model.fit(\n",
        "            X,\n",
        "            y,\n",
        "            validation_split=0.2,\n",
        "            batch_size = hp.Int(\"batch_size\", 4,36,step=8),\n",
        "            **kwargs,\n",
        "        )   \n",
        "        \n",
        "tuner = keras_tuner.RandomSearch(\n",
        "    VGG16HyperModel(),\n",
        "    objective=\"val_accuracy\",\n",
        "    overwrite=True,\n",
        "    executions_per_trial = 2,\n",
        "    max_trials=20,\n",
        "    directory=\"vgg16_tuner\",\n",
        "    project_name='vgg16'\n",
        ")\n",
        "print(tuner.search_space_summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "WMhhuwvtu0k3"
      },
      "outputs": [],
      "source": [
        "# # a quick test\n",
        "# hp = keras_tuner.HyperParameters()\n",
        "# hypermodel = VGG16HyperModel()\n",
        "# model = hypermodel.build(hp)\n",
        "# hypermodel.fit(hp, model, vgg16features, y_cnn_train, epochs = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "LromWRE9LCW7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "691a9d27-6085-43a8-c41a-b68cd5d3d60a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 20 Complete [00h 00m 27s]\n",
            "val_accuracy: 0.12187500298023224\n",
            "\n",
            "Best val_accuracy So Far: 0.6968750059604645\n",
            "Total elapsed time: 00h 07m 10s\n"
          ]
        }
      ],
      "source": [
        "# search begain\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
        "# uncomment this\n",
        "tuner.search(X_cnn_train, y_cnn_train,callbacks = [keras.callbacks.TensorBoard(\"vgg16_tuner\")], epochs = 5)\n",
        "# tuner.search(vgg16features, y_cnn_train,callbacks = [keras.callbacks.TensorBoard(\"mlp_tuner\")], epochs = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Frv-uCHQLCXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4b6c659-6c8b-4104-c1ff-0ce16ee1ab94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "32/32 [==============================] - 2s 15ms/step - loss: 103.1763 - accuracy: 0.2019 - val_loss: 3.8038 - val_accuracy: 0.4375\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.8514 - accuracy: 0.5806 - val_loss: 1.9542 - val_accuracy: 0.4938\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6502 - accuracy: 0.7919 - val_loss: 1.1431 - val_accuracy: 0.6438\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.1966 - accuracy: 0.9374 - val_loss: 1.8633 - val_accuracy: 0.5688\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.1110 - accuracy: 0.9671 - val_loss: 1.0852 - val_accuracy: 0.7125\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0229 - accuracy: 0.9969 - val_loss: 1.0442 - val_accuracy: 0.7312\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 1.0897 - val_accuracy: 0.7063\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0146 - accuracy: 0.9969 - val_loss: 1.1408 - val_accuracy: 0.7188\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.0751 - val_accuracy: 0.7437\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1192 - val_accuracy: 0.7500\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 8.2691e-04 - accuracy: 1.0000 - val_loss: 1.1270 - val_accuracy: 0.7500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc5b83fa3e0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "vgg16_hp_model = VGG16HyperModel()\n",
        "best_vgg16_hp = tuner.get_best_hyperparameters()[0]\n",
        "best_vgg16_model = vgg16_hp_model.build(best_vgg16_hp)\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
        "vgg16_hp_model.fit(best_vgg16_hp, best_vgg16_model, X_cnn_train, y_cnn_train, verbose=1, epochs = 50, callbacks=[early_stop])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_vgg16_model.save_weights(\"best_vgg16_model.h5\")"
      ],
      "metadata": {
        "id": "1oHRfhBheCth"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy on the test set\n",
        "test_accuracy_vgg16 = best_vgg16_model.evaluate(X_cnn_test,y_cnn_test,verbose=1)\n",
        "print(test_accuracy_vgg16[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baJM8lbHeB1I",
        "outputId": "20f1eb9a-6f53-4dc7-cf66-541b4daacbaf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 5ms/step - loss: 1.6074 - accuracy: 0.6750\n",
            "0.675000011920929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "XHx4V_KQSBsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72659837-43d1-4d3e-aa19-9d9519146615"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'units_1': 2560,\n",
              " 'dropout_1': False,\n",
              " 'units_2': 1536,\n",
              " 'dropout_2': False,\n",
              " 'units_3': 416,\n",
              " 'dropout_3': False,\n",
              " 'has_forth_layer': False,\n",
              " 'dropout_4': False,\n",
              " 'learning_rate': 0.001,\n",
              " 'batch_size': 20}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "best_vgg16_hp.values"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary for VGG16\n",
        "Accuracy is 65.5% on the test set. Run 9 epochs on,\n",
        "```python\n",
        "{\n",
        " 'activation': 'relu', 'units_1': 3072, 'dropout_1': True,\n",
        " 'units_2': 1536, 'dropout_2': False, 'units_3': 288,\n",
        " 'dropout_3': False, 'has_forth_layer': False, 'dropout_4': False,\n",
        " 'learning_rate': 0.001, 'units_4': 736, 'batch_size': 28, \n",
        " 'epochs': 6\n",
        " }\n",
        "```\n",
        "Try two ways to scale data, 1. images/255; 2. use vgg16 preprocess, but no preprocess gave the best result, this."
      ],
      "metadata": {
        "id": "jDwzn1WJnl6o"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}